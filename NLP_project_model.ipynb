{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMVcwajXskw5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPyQJa8J_hz2"
      },
      "outputs": [],
      "source": [
        "EN_LEN = 100\n",
        "DEC_LEN = 100\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = BATCH_SIZE*4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m wget 'https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-mr.zip'\n",
        "# !python -m wget 'https://storage.googleapis.com/samanantar-public/V0.2/data/en2indic/en-hi.zip'"
      ],
      "metadata": {
        "id": "0fHwO1fMrlHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip en-hi.zip"
      ],
      "metadata": {
        "id": "W0xuFqLDrpzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f = open(trainfileEH, \"r\")\n",
        "# EnglishV = f.readlines()\n",
        "# f.close()\n",
        "# EnglishV = removeNewLineChars(EnglishV)\n",
        "# print(f\"Total English Sentences : {len(EnglishV)}\")"
      ],
      "metadata": {
        "id": "0ehRbX2Gq--n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f = open(trainfileEH, \"r\")\n",
        "# HindiV = f.readlines()\n",
        "# f.close()\n",
        "# HindiV = removeNewLineChars(HindiV)\n",
        "# print(f\"Total Hindi Sentences : {len(EnglishV)}\")"
      ],
      "metadata": {
        "id": "3enKrL33r4HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df = pd.DataFrame(list(zip(EnglishV, HindiV)), columns=[\"english_sentence\", 'hindi_sentence'])"
      ],
      "metadata": {
        "id": "qzynZ2hUsK4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x54HW85c_i8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0f39d426-f03f-4806-ab0a-4fe178a6b27a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        english_sentence  \\\n",
              "73642  <SOS> And all you can think about is that oppo...   \n",
              "81218  <SOS> She has got awards from administrative, ...   \n",
              "19190  <SOS> The member whose question has been admit...   \n",
              "73887  <SOS> 7 . We will consider your application ca...   \n",
              "67379           <SOS> Class: Nobel Prize Recepient <EOS>   \n",
              "\n",
              "                                          hindi_sentence  \n",
              "73642  <SOS> और आप एक ही बात सोच रहे होते हैं कि सुधा...  \n",
              "81218  <SOS> उन्हें प्रशासनिक अर्धप्रशासनिक और व्यक्त...  \n",
              "19190  <SOS> प्रश्न किस प्रकार पूछे जाते हैं जिस सदस्...  \n",
              "73887  <SOS> 7 हम आप के आवेदन पत्र पर वर्क परमिट के द...  \n",
              "67379         <SOS> श्रेणी:नोबेल पुरस्कार सम्मानित <EOS>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38abfb00-b7bb-4d92-a7d5-7493f4dde9e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73642</th>\n",
              "      <td>&lt;SOS&gt; And all you can think about is that oppo...</td>\n",
              "      <td>&lt;SOS&gt; और आप एक ही बात सोच रहे होते हैं कि सुधा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81218</th>\n",
              "      <td>&lt;SOS&gt; She has got awards from administrative, ...</td>\n",
              "      <td>&lt;SOS&gt; उन्हें प्रशासनिक अर्धप्रशासनिक और व्यक्त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19190</th>\n",
              "      <td>&lt;SOS&gt; The member whose question has been admit...</td>\n",
              "      <td>&lt;SOS&gt; प्रश्न किस प्रकार पूछे जाते हैं जिस सदस्...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73887</th>\n",
              "      <td>&lt;SOS&gt; 7 . We will consider your application ca...</td>\n",
              "      <td>&lt;SOS&gt; 7 हम आप के आवेदन पत्र पर वर्क परमिट के द...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67379</th>\n",
              "      <td>&lt;SOS&gt; Class: Nobel Prize Recepient &lt;EOS&gt;</td>\n",
              "      <td>&lt;SOS&gt; श्रेणी:नोबेल पुरस्कार सम्मानित &lt;EOS&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38abfb00-b7bb-4d92-a7d5-7493f4dde9e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38abfb00-b7bb-4d92-a7d5-7493f4dde9e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38abfb00-b7bb-4d92-a7d5-7493f4dde9e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "train_df = pd.read_csv(\"https://raw.githubusercontent.com/saurabhburewar/ML_English-to-Hindi-Language-translation/main/data/Hindi_English_Truncated_Corpus.csv\")\n",
        "train_df.drop(['source'],axis=1,inplace=True)\n",
        "for index, row in train_df.iterrows():\n",
        "  if len(str(row['english_sentence'])) < 20 and len(str(row['english_sentence'])) > 200:\n",
        "    train_df.drop(index=index, inplace=True)\n",
        "  else:\n",
        "    row['english_sentence'] = \"<SOS> \" + str(row['english_sentence']) + \" <EOS>\"\n",
        "    row['hindi_sentence'] = \"<SOS> \" + row['hindi_sentence'] + \" <EOS>\"\n",
        "train_df = train_df.sample(64000, random_state=1)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT2qIjiY_oRQ"
      },
      "outputs": [],
      "source": [
        "tokenizerEng = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<unk>')\n",
        "tokenizerHindi = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<unk>')\n",
        "tokenizerEng.fit_on_texts(train_df['english_sentence'])\n",
        "tokenizerHindi.fit_on_texts(train_df['hindi_sentence'])\n",
        "\n",
        "input = tokenizerEng.texts_to_sequences(train_df['english_sentence'])\n",
        "target = tokenizerHindi.texts_to_sequences(train_df['hindi_sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UIHdWVH_pqt",
        "outputId": "7f8529e5-f99b-48fe-b421-a75af159e4a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47585 56905\n"
          ]
        }
      ],
      "source": [
        "vocabEnc = len(tokenizerEng.word_index) + 1\n",
        "vocabDec = len(tokenizerHindi.word_index) + 1\n",
        "print(vocabEnc, vocabDec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jedKqHE_rBV"
      },
      "outputs": [],
      "source": [
        "input = tf.keras.preprocessing.sequence.pad_sequences(input, maxlen=EN_LEN, padding='post', truncating='post')\n",
        "target = tf.keras.preprocessing.sequence.pad_sequences(target, maxlen=DEC_LEN, padding='post', truncating='post')\n",
        "input = tf.cast(input, dtype=tf.int64)\n",
        "target = tf.cast(target, dtype=tf.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sshBsM1A_sCm"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((input, target)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zilVpQud_uFe"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(position, model):\n",
        "    i = np.arange(model)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(model))\n",
        "    angle_rads = np.arange(position)[:, np.newaxis] * angle_rates\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjJPb9Df_utm"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        \n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "            \n",
        "        return output, attention_weights\n",
        "    \n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2bEwnGB_yab"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFHpEtRA_z_I"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQjv5NB7_1xU"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "        self.enc_layers = []\n",
        "        for _ in range(num_layers):\n",
        "          self.enc_layers.append(EncoderLayer(d_model, num_heads, dff, rate))\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "    \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "        return x\n",
        "    \n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "        \n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = []\n",
        "        for _ in range(num_layers):\n",
        "          self.dec_layers.append(DecoderLayer(d_model, num_heads, dff, rate))\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        # attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x  = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "    \n",
        "        return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuaC4RGw_27_"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dkq9XC_c_3DL"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYByi441_5Ms"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(tf.math.rsqrt(step), (step * (self.warmup_steps ** -1.5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EERcfOs7_5Ow"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "X4ZmqFNk_5Rf",
        "outputId": "00f9773d-7bba-4543-c386-a14dc5b919af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.CustomSchedule object at 0x7f84b1eb9590>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "print(temp_learning_rate_schedule)\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKjhsUoS_5Ts"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig51p5-_AAOK"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qubqcBF1AAQt"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=vocabEnc,\n",
        "    target_vocab_size=vocabDec,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlzwePcHAAa0"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rnflZ5BAAdz"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar_inp)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar_inp)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = transformer(\n",
        "            inp, tar_inp, \n",
        "            True, \n",
        "            enc_padding_mask, \n",
        "            combined_mask, \n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(tar_real, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql-QXnNVAPNi"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "        if batch % 200 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "      \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "   \n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6u4HjfOQAAgk"
      },
      "outputs": [],
      "source": [
        "def evaluate(text):\n",
        "    text = tokenizerEng.texts_to_sequences([text])\n",
        "    text = tf.keras.preprocessing.sequence.pad_sequences(text, maxlen=EN_LEN, \n",
        "                                                                   padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(text[0], 0)\n",
        "\n",
        "    decoder_input = [tokenizerHindi.word_index['<sos>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(DEC_LEN):\n",
        "        enc_padding_mask = create_padding_mask(encoder_input)\n",
        "        dec_padding_mask = create_padding_mask(encoder_input)\n",
        "\n",
        "        look_ahead_mask = create_look_ahead_mask(tf.shape(output)[1])\n",
        "        dec_target_padding_mask = create_padding_mask(output)\n",
        "        combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "        predictions = transformer(\n",
        "            encoder_input, \n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == tokenizerHindi.word_index['<eos>']:\n",
        "            return tf.squeeze(output, axis=0)\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E_zMIEnAAi9"
      },
      "outputs": [],
      "source": [
        "def translator(eng_text):\n",
        "    hind_text = evaluate(eng_text).numpy()\n",
        "    hind_text = np.expand_dims(hind_text[1:], 0)  \n",
        "    return tokenizerHindi.sequences_to_texts(hind_text)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQXl_lwsAAlz"
      },
      "outputs": [],
      "source": [
        "translator(\"That politics , in retrospect , was rooted in a false ideology\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"I spend a few hours a day maintaining my website.\",\n",
        "        \"Where do random thoughts come from?\",\n",
        "        \"\tI can't believe that she is older than my mother.\",\n",
        "        \"My Mum tries to be cool by saying that she likes all the same things that I do\",\n",
        "        \"A song can make or ruin a person’s day if they let it get to them.\"]\n",
        "\n",
        "for text in texts:\n",
        "  print(\"English Text: \", text)\n",
        "  print(\"Hindi Translation: \", translator(text))\n",
        "  print(\"*\"*50,\"\\n\")"
      ],
      "metadata": {
        "id": "yX6DfvJjxg-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"And who are we to say, even, that they are wrong\",\n",
        "        \"So there is some sort of justice\",\n",
        "        \"The first two were found unreliable and the prosecution case rested mainly on the evidence of the remaining five approvers\",\n",
        "        \"Naren had three or four meetings with the Consul but found that he was making no progress\",\n",
        "        \"Of these Lahadi is a popular one .\"]\n",
        "\n",
        "for text in texts:\n",
        "  print(\"English Text: \", text)\n",
        "  print(\"Hindi Translation: \", translator(text))\n",
        "  print(\"*\"*50,\"\\n\")"
      ],
      "metadata": {
        "id": "1EUiG-RyxjMm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of NLP_project_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}